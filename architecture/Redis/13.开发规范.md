# 开发规范
## 1、单个简单的key存储的value很大
- 该对象需要每次都整存整取
  - 可以尝试将对象分拆成几个key-value， 使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响；
- 该对象每次只需要存取部分数据
  - 可以像第一种做法一样，分拆成几个key-value， 也可以将这个存储在一个hash中，每个field代表一个具体的属性， 使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性
## 2、hash， set，zset，list 中存储过多的元素（以万为单位）
- 类似于场景一种的第一个做法，可以将这些元素分拆。
- 以hash为例，原先的正常存取流程是 hget(hashKey, field) ; hset(hashKey, field, value)
  - 现在，固定一个桶的数量，比如 10000， 每次存取的时候，先在本地计算field的hash值，模除 10000， 确定了该field落在哪个key上。
  - newHashKey = hashKey + (set, zset, list 也可以类似上述做法但有些不适合的场景，比如，要保证 lpop 的数据的确是最早push到list中去的，这个就需要一些附加的属性，或者是在 key的拼接上做一些工作（比如list按照时间来分拆）。
## 3、一个集群存储了上亿的key，Key 本身过多也带来了更多的空间占用
- 如果key的个数过多会带来更多的内存空间占用，
  - key本身的占用（每个key 都会有一个Category前缀）
  - 集群模式中，服务端需要建立一些slot2key的映射关系，这其中的指针占用在key多的情况下也是浪费巨大空间这两个方面在key个数上亿的时候消耗内存十分明显（Redis 3.2及以下版本均存在这个问题，4.0有优化）；
- 优化方案
  - 所以减少key的个数可以减少内存消耗，可以参考的方案是转Hash结构存储，即原先是直接使用Redis String 的结构存储，现在将多个key存储在一个Hash结构中，具体场景参考如下
  - key 本身就有很强的相关性，比如多个key 代表一个对象，每个key是对象的一个属性，这种可直接按照特定对象的特征来设置一个新Key——Hash结构， 原先的key则作为这个新Hash 的field。
  - key 本身没有相关性，预估一下总量，采取和上述第二种场景类似的方案，预分一个固定的桶数量比如现在预估key 的总数为 2亿，按照一个hash存储 100个field来算，需要 2亿 / 100 = 200W 个桶 (200W 个key占用的空间很少，2亿可能有将近 20G )

## 4、大Bitmap或布隆过滤器（Bloom ）拆分
